---
title: "Analysis of topics about cryptocurrencies on Reddit"
author: "Riccardo Ferrarese"
date: "19/3/2021"
output:
  pdf_document: 
    latex_engine: xelatex
    toc: true
    toc_depth: 2
  html_document:
    df_print: paged
---

## PANCAKE SWAP

```{r setup, echo=FALSE}
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60), tidy=TRUE, 
                      python.reticulate=FALSE, 
                      echo = TRUE, 
                      warning = FALSE, 
                      cache = TRUE, 
                      message = FALSE, 
                      results = 'hide', 
                      out.width = "80%"
)
knitr::knit_hooks$set(crop = knitr::hook_pdfcrop) 


```
   
Come prima cosa scarichiamo i dati riguardanti il subreddit da analizzare.

```{r}

source("../src/lib.R")
save <- FALSE
dataset <- 'pancakeswap'

com_raw_data <- read.csv("../Data/src/pancakeswap_com.csv")


# create and save data (df + corpus)
data = df.create(com_raw_data, "../Data/", dataset, filter_post = 0)

remove(doge_com_raw_data)
    
```

Facciamo un summary dei dataframe per venderne il contenuto: 

```{r}
if(save){ data <- readRDS(paste0("../Data/", dataset, ".rds")) }

print_("REDDIT's COMMENT DF: ")
data$df_comm %>%
   select(id, date, author)
print_("REDDIT's POST DF: ")
summary(data$df_post)
```

```{r, crop=TRUE}

if(save){ data <- readRDS(paste0("../Data/", dataset, ".rds")) }
com_corpus <- data$corpus_comm
remove(data)

# remove stopwords!!              
tidy <- corpus.tokenize_dfmTidy(com_corpus, 
                                     spell_checking = TRUE, 
                                     mode_correction = 0)
clean_tidy <- corpus.clean_tidy(tidy$tidy, mode='stem' )
word_counts <- corpus.countPlot_tidy(clean_tidy, threshold_count = 5)
remove(clean_tidy)
```

```{r, crop=TRUE}

set.seed(190)

dff <- tidy$dfm
# colour of words from least to most frequent
textplot_wordcloud(dff, min_count = 200,
     color = c('pink', 'red', 'green3', 'purple', 'orange', 'blue3'))
remove(dff)
```

Tra le parole più presenti, oltre a doge, possiamo notare parole come: 
- buy
- hold
- moon
- invest/keep


```{r crop=TRUE}
words.classSentiment(word_counts)
```

Tenendo conto che molte parole, magari offensive, vengano utilizzante in discussioni che non c'entrano molto con il mercato della moneta, la divisione in classi dei sentimenti ci fa vedere come ci sia 


```{r crop=TRUE}
word_sentiment <- words.computeSentiment(word_counts, n_filter = 10)
```

In questo grafico possiamo trovare parole interessanti divise in base alla loro positività. Nella parte negativa si può notare subito come 'dump', termine che in finanza significherebbe far sgonfiare il prezzo, sia molto utilizzata e attorno una serie di parole che non sono legate alla fiducia, ma al contrario fanno capire come il mercato di questa moneta non sia percepito come non stabile. Dall'altra parte ci sono parole che cercano di ingoraggiare all'investimento in dogecoin. 

Andiamo però a visualizzare i bigrammi per vedere se queste parole prese con un minimo di contesto facciano presumere le stesse ipotesi. 


```{r include = FALSE}
remove(word_counts)
remove(word_sentiment)
```


```{r  crop=TRUE}

tidy_bigrams <- corpus.tokenize_dfmTidy(com_corpus, 
                                          dfm_b = FALSE,
                                          spell_checking = FALSE, 
                                          ngrams=2)

clean_tidy_bigrams <- corpus.clean_tidy(tidy_bigrams$tidy,
                                                     ngrams = 2)
remove(tidy_bigrams)
bigrams_counts <- corpus.countPlot_tidy(clean_tidy_bigrams, 
                                        threshold_count = 25,
                                                   ngrams = 2)

```

Analizzando i bigrammi si può notare ancor più maggiormente che la gran parte delle parole si riferiscono a spingere gli utenti ad acquistare e mantenere i dogecoin nel proprio wallet digitale. 

```{r crop=TRUE}
bigrams_class_sentiment <- words.classSentiment(bigrams_counts, n_filter_sentiment = 200, ngrams = 2)
```

Considerando le classi dei sentimenti sui bigrammi la situazione cambia un poco. Infatti i sentimenti positivi risultano maggiori, ma sempre con un po' di incertezza considerando i bigrammi in cui viene associato il sentimento di fiducia con sentimenti negativi. 

```{r  crop=TRUE}
bigrams_sentiment <- words.computeSentiment(bigrams_counts, n_filter = 2, ngrams = 2)
#saveRDS(bigrams_sentiment, paste0("../Data/", dataset, "_bigrams_sentiment.rds")
```
Similmente andando a classificare ciascuna parola in una scala da 0 a 1, che indica la positività di un bigramma, il numero di parole negative sembra essere molto minore a quelle positive. 

```{r  crop=TRUE}
words.network(bigrams_counts, n_filter = 30)
```

Dalle rete delle parole, con conteggi superiori a 2000, possiamo cogliere altre informazioni molto interessanti, come l'accostamento delle parole right e dips, che in ambito finanziario si potrebbero associare allo slogan "Buy the dips", con il significato di comprare un asset successivamente al suo crollo di prezzo. Un'altra osservazione può esser fatta sulla parola "buy" che presenta un numero di archi collegati superiore alla maggior parte delle parole oltre a 'doge'. 
   
Inoltre, a confermare l'ipotesi che gli utenti spingano all'acquisto e possesso di questa cryptovaluta, c'è l'accostamento della parola "stop" con "selling", proprio per incentivare a non vendere e quindi a non far calare di prezzo il valore dei dogecoin. 
 

```{r}
remove(tidy_bigrams, clean_tidy_bigrams)
remove(bigrams_counts)

remove(bigrams_class_sentiment)
remove(bigrams_sentiment)
```


## BITCOIN - SubReddit

Come prima cosa scarichiamo i dati riguardanti il subreddit da analizzare.
Nel Dataset riguardante il subreddit di Reddit abbiamo un milione e seicento mila osservazioni, per limitare l'uso di memoria si va ad analizzare solo i commenti in merito all'anno 2021. 

```{r }

save = FALSE
dataset='bitcoin'

com_raw_data <- read.csv("../Data/src/Bitcoin_com.csv")


# create and save data (df + corpus)
data = df.create(com_raw_data, "../Data/", dataset, filter_post = 0)

remove(com_raw_data)
    
```

Facciamo un summary dei dataframe per venderne il contenuto: 

```{r}
if(save){ data <- readRDS(paste0("../Data/", dataset, ".rds")) }

print_("REDDIT's COMMENT DF: ")
data$df_comm %>%
   select(id, date, author)
print_("REDDIT's POST DF: ")
summary(data$df_post)
```

```{r, crop=TRUE}

if(save){ data <- readRDS(paste0("../Data/", dataset, ".rds")) }
com_corpus <- data$corpus_comm
remove(data)

docvars(com_corpus)

# filter 2021 post with quanteda library 
com_corpus_ <- corpus_subset(com_corpus, data > as.Date("2020-12-31") )
remove(com_corpus)

# remove stopwords!!              
tidy <- corpus.tokenize_dfmTidy(com_corpus_, 
                                     spell_checking = TRUE )

  
clean_tidy <- corpus.clean_tidy(tidy$tidy, mode='stem' )
word_counts <- corpus.countPlot_tidy(clean_tidy, threshold_count = 1000)
remove(clean_tidy)
```

```{r, crop=TRUE}

set.seed(190)

dff <- tidy$dfm
# colour of words from least to most frequent
textplot_wordcloud(dff, min_count = 10000,
     color = c('grey', 'red', 'green3', 'purple', 'orange', 'blue3'))
```


```{r}
remove(dff, tidy)
```

```{r  crop=TRUE}
words.classSentiment(word_counts)
```

```{r  crop=TRUE}
word_sentiment <- words.computeSentiment(word_counts, n_filter = 10)
```


```{r include = FALSE}
remove(word_counts, word_sentiment, word_sentiment)
```


```{r  crop=TRUE}

tidy_bigrams <- corpus.tokenize_dfmTidy(com_corpus_, 
                                          dfm_b = FALSE,
                                          spell_checking = FALSE, 
                                          ngrams=2)

clean_tidy_bigrams <- corpus.clean_tidy(tidy_bigrams$tidy,
                                                     ngrams = 2)
remove(tidy_bigrams)
bigrams_counts <- corpus.countPlot_tidy(clean_tidy_bigrams, 
                                        threshold_freq = 0.001,
                                        threshold_count = 9000,
                                                   ngrams = 2)

```


```{r  crop=TRUE}
bigrams_class_sentiment <- words.classSentiment(bigrams_counts, n_filter_sentiment = 200, ngrams = 2)
```


```{r crop=TRUE}
bigrams_sentiment <- words.computeSentiment(bigrams_counts, n_filter = 2, ngrams = 2)
#saveRDS(bigrams_sentiment, paste0("../Data/", dataset, "_bigrams_sentiment.rds")
```


```{r crop=TRUE}
words.network(bigrams_counts, n_filter = 30)
```

Dalle rete delle parole, con conteggi superiori a 2000, possiamo cogliere altre informazioni molto interessanti, come l'accostamento delle parole right e dips, che in ambito finanziario si potrebbero associare allo slogan "Buy the dips", con il significato di comprare un asset successivamente al suo crollo di prezzo. Un'altra osservazione può esser fatta sulla parola "buy" che presenta un numero di archi collegati superiore alla maggior parte delle parole oltre a 'doge'. 
   
Inoltre, a confermare l'ipotesi che gli utenti spingano all'acquisto e possesso di questa cryptovaluta, c'è l'accostamento della parola "stop" con "selling", proprio per incentivare a non vendere e quindi a non far calare di prezzo il valore dei dogecoin. 
 

```{r}
remove(tidy_bigrams)
remove(bigrams_counts)

remove(bigrams_class_sentiment)
remove(bigrams_sentiment)
```


## ETHEREUM 

Come prima cosa scarichiamo i dati riguardanti il subreddit da analizzare.

```{r }

save = FALSE
dataset='ethtrader'

com_raw_data <- read.csv("../Data/src/ethtrader_com.csv")


# create and save data (df + corpus)
data = df.create(com_raw_data, "../Data/", dataset, filter_post = 0)

remove(com_raw_data)
    
```

Facciamo un summary dei dataframe per venderne il contenuto: 

```{r}
if(save){ data <- readRDS(paste0("../Data/", dataset, ".rds")) }

print_("REDDIT's COMMENT DF: ")
data$df_comm %>%
   select(id, date, author)
print_("REDDIT's POST DF: ")
summary(data$df_post)
```

```{r, crop=TRUE}

if(save){ data <- readRDS(paste0("../Data/", dataset, ".rds")) }
com_corpus <- data$corpus_comm
remove(data)

# remove stopwords!!              
tidy <- corpus.tokenize_dfmTidy(com_corpus, 
                                     spell_checking = TRUE, 
                                     mode_correction = 0)
clean_tidy <- corpus.clean_tidy(tidy$tidy, mode='stem' )
word_counts <- corpus.countPlot_tidy(clean_tidy, threshold_count = 5)
remove( clean_tidy)
```

```{r, crop=TRUE}

set.seed(190)

dff <- tidy$dfm
# colour of words from least to most frequent
textplot_wordcloud(dff, min_count = 200,
     color = c('pink', 'red', 'green3', 'purple', 'orange', 'blue3'))
remove(dff, tidy)
```

Tra le parole più presenti, oltre a doge, possiamo notare parole come: 
- buy
- hold
- moon
- invest/keep


```{r  crop=TRUE}
words.classSentiment(word_counts)
```

Tenendo conto che molte parole, magari offensive, vengano utilizzante in discussioni che non c'entrano molto con il mercato della moneta, la divisione in classi dei sentimenti ci fa vedere come ci sia 


```{r  crop=TRUE}
doge_word_sentiment <- words.computeSentiment(word_counts, n_filter = 10)
```

In questo grafico possiamo trovare parole interessanti divise in base alla loro positività. Nella parte negativa si può notare subito come 'dump', termine che in finanza significherebbe far sgonfiare il prezzo, sia molto utilizzata e attorno una serie di parole che non sono legate alla fiducia, ma al contrario fanno capire come il mercato di questa moneta non sia percepito come non stabile. Dall'altra parte ci sono parole che cercano di ingoraggiare all'investimento in dogecoin. 

Andiamo però a visualizzare i bigrammi per vedere se queste parole prese con un minimo di contesto facciano presumere le stesse ipotesi. 


```{r include = FALSE}
remove(word_counts)
remove(word_sentiment)
```


```{r crop=TRUE}

tidy_bigrams <- corpus.tokenize_dfmTidy(com_corpus, 
                                          dfm_b = FALSE,
                                          spell_checking = FALSE, 
                                          ngrams=2)

clean_tidy_bigrams <- corpus.clean_tidy(tidy_bigrams$tidy,
                                                     ngrams = 2)
remove(tidy_bigrams)
bigrams_counts <- corpus.countPlot_tidy(clean_tidy_bigrams, 
                                        threshold_count = 25,
                                                   ngrams = 2)

```

Analizzando i bigrammi si può notare ancor più maggiormente che la gran parte delle parole si riferiscono a spingere gli utenti ad acquistare e mantenere i dogecoin nel proprio wallet digitale. 

```{r crop=TRUE}
bigrams_class_sentiment <- words.classSentiment(bigrams_counts, n_filter_sentiment = 200, ngrams = 2)
```

Considerando le classi dei sentimenti sui bigrammi la situazione cambia un poco. Infatti i sentimenti positivi risultano maggiori, ma sempre con un po' di incertezza considerando i bigrammi in cui viene associato il sentimento di fiducia con sentimenti negativi. 

```{r crop=TRUE}
bigrams_sentiment <- words.computeSentiment(bigrams_counts, n_filter = 2, ngrams = 2)
#saveRDS(bigrams_sentiment, paste0("../Data/", dataset, "_bigrams_sentiment.rds")
```
Similmente andando a classificare ciascuna parola in una scala da 0 a 1, che indica la positività di un bigramma, il numero di parole negative sembra essere molto minore a quelle positive. 

```{r crop=TRUE}
words.network(bigrams_counts, n_filter = 30)
```

Dalle rete delle parole, con conteggi superiori a 2000, possiamo cogliere altre informazioni molto interessanti, come l'accostamento delle parole right e dips, che in ambito finanziario si potrebbero associare allo slogan "Buy the dips", con il significato di comprare un asset successivamente al suo crollo di prezzo. Un'altra osservazione può esser fatta sulla parola "buy" che presenta un numero di archi collegati superiore alla maggior parte delle parole oltre a 'doge'. 
   
Inoltre, a confermare l'ipotesi che gli utenti spingano all'acquisto e possesso di questa cryptovaluta, c'è l'accostamento della parola "stop" con "selling", proprio per incentivare a non vendere e quindi a non far calare di prezzo il valore dei dogecoin. 
 

```{r}
remove(tidy_bigrams)
remove(bigrams_counts)

remove(bigrams_class_sentiment)
remove(bigrams_sentiment)
```

## ELON MUSK 

Come prima cosa scarichiamo i dati riguardanti il subreddit da analizzare.

```{r }

save = FALSE
dataset='elonmusk'

com_raw_data <- read.csv("../Data/src/elonmusk_com.csv")


# create and save data (df + corpus)
data = df.create(com_raw_data, "../Data/", dataset, filter_post = 0)

remove(com_raw_data)
    
```

Facciamo un summary dei dataframe per venderne il contenuto: 

```{r}
if(save){ data <- readRDS(paste0("../Data/", dataset, ".rds")) }

print_("REDDIT's COMMENT DF: ")
data$df_comm %>%
   select(id, date, author)
print_("REDDIT's POST DF: ")
summary(data$df_post)
```

```{r, crop=TRUE}

if(save){ data <- readRDS(paste0("../Data/", dataset, ".rds")) }
com_corpus <- data$corpus_comm
remove(data)

# remove stopwords!!              
tidy <- corpus.tokenize_dfmTidy(com_corpus, 
                                     spell_checking = TRUE, 
                                     mode_correction = 0)
clean_tidy <- corpus.clean_tidy(tidy$tidy, mode='stem' )
word_counts <- corpus.countPlot_tidy(clean_tidy, threshold_count = 100)
remove( clean_tidy)
```

```{r, crop=TRUE}

set.seed(190)

dff <- tidy$dfm
# colour of words from least to most frequent
textplot_wordcloud(dff, min_count = 200,
     color = c('pink', 'red', 'green3', 'purple', 'orange', 'blue3'))
remove(dff)
```

Tra le parole più presenti, oltre a doge, possiamo notare parole come: 
- buy
- hold
- moon
- invest/keep


```{r crop=TRUE}
words.classSentiment(word_counts)
```

Tenendo conto che molte parole, magari offensive, vengano utilizzante in discussioni che non c'entrano molto con il mercato della moneta, la divisione in classi dei sentimenti ci fa vedere come ci sia 


```{r  crop=TRUE}
doge_word_sentiment <- words.computeSentiment(word_counts, n_filter = 10)
```

In questo grafico possiamo trovare parole interessanti divise in base alla loro positività. Nella parte negativa si può notare subito come 'dump', termine che in finanza significherebbe far sgonfiare il prezzo, sia molto utilizzata e attorno una serie di parole che non sono legate alla fiducia, ma al contrario fanno capire come il mercato di questa moneta non sia percepito come non stabile. Dall'altra parte ci sono parole che cercano di ingoraggiare all'investimento in dogecoin. 

Andiamo però a visualizzare i bigrammi per vedere se queste parole prese con un minimo di contesto facciano presumere le stesse ipotesi. 


```{r include = FALSE}
remove(word_counts)
remove(word_sentiment)
```


```{r  crop=TRUE}

tidy_bigrams <- corpus.tokenize_dfmTidy(com_corpus, 
                                          dfm_b = FALSE,
                                          spell_checking = FALSE, 
                                          ngrams=2)

clean_tidy_bigrams <- corpus.clean_tidy(tidy_bigrams$tidy,
                                                     ngrams = 2)
remove(tidy_bigrams)
bigrams_counts <- corpus.countPlot_tidy(clean_tidy_bigrams, 
                                        threshold_count = 25,
                                                   ngrams = 2)

```

Analizzando i bigrammi si può notare ancor più maggiormente che la gran parte delle parole si riferiscono a spingere gli utenti ad acquistare e mantenere i dogecoin nel proprio wallet digitale. 

```{r  crop=TRUE}
bigrams_class_sentiment <- words.classSentiment(bigrams_counts, n_filter_sentiment = 2000, ngrams = 2)
```

Considerando le classi dei sentimenti sui bigrammi la situazione cambia un poco. Infatti i sentimenti positivi risultano maggiori, ma sempre con un po' di incertezza considerando i bigrammi in cui viene associato il sentimento di fiducia con sentimenti negativi. 

```{r  crop=TRUE}
bigrams_sentiment <- words.computeSentiment(bigrams_counts, n_filter = 2, ngrams = 2)
#saveRDS(bigrams_sentiment, paste0("../Data/", dataset, "_bigrams_sentiment.rds")
```
Similmente andando a classificare ciascuna parola in una scala da 0 a 1, che indica la positività di un bigramma, il numero di parole negative sembra essere molto minore a quelle positive. 

```{r crop=TRUE}
words.network(bigrams_counts, n_filter = 30)
```

Dalle rete delle parole, con conteggi superiori a 2000, possiamo cogliere altre informazioni molto interessanti, come l'accostamento delle parole right e dips, che in ambito finanziario si potrebbero associare allo slogan "Buy the dips", con il significato di comprare un asset successivamente al suo crollo di prezzo. Un'altra osservazione può esser fatta sulla parola "buy" che presenta un numero di archi collegati superiore alla maggior parte delle parole oltre a 'doge'. 
   
Inoltre, a confermare l'ipotesi che gli utenti spingano all'acquisto e possesso di questa cryptovaluta, c'è l'accostamento della parola "stop" con "selling", proprio per incentivare a non vendere e quindi a non far calare di prezzo il valore dei dogecoin. 
 

```{r}
remove(tidy_bigrams)
remove(bigrams_counts)

remove(bigrams_class_sentiment)
remove(bigrams_sentiment)
```

